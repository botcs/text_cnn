{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "    1. Read from 'movie-lines.txt'\n",
    "    2. Create a dictionary with ( key = line_id, value = text )\n",
    "'''\n",
    "def get_id2line():\n",
    "    with codecs.open('./updated_movie_lines.txt', \n",
    "                     'r', encoding='utf-8', errors='ignore') as fdata:\n",
    "        lines= fdata.read().split('\\n')\n",
    "    id2line = {}\n",
    "    for line in lines:\n",
    "        _line = line.split(' +++$+++ ')\n",
    "        if len(_line) == 5:\n",
    "            id2line[_line[0]] = _line[4]\n",
    "        else:\n",
    "            id2line[_line[0]] = ' '\n",
    "    return id2line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    1. Read from 'movie_titles_metadata.txt'\n",
    "    2. Create a dictionary with ( key = movie_id, value = [genre1, genre2, ..])\n",
    "'''\n",
    "def get_id2genre():\n",
    "    with codecs.open('./corpus/movie_titles_metadata.txt', \n",
    "                     'r', encoding='utf-8', errors='ignore') as fdata:\n",
    "        lines= fdata.read().split('\\n')\n",
    "        \n",
    "    id2genre = {}\n",
    "    for line in lines:\n",
    "        _line = line.split(' +++$+++ ')\n",
    "        if len(_line) == 6:\n",
    "            id2genre[_line[0]] = _line[-1][1:-1].replace(\"'\",\"\")\n",
    "    return id2genre        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    1. Read from 'movie_conversations.txt'\n",
    "    2. Create a list of [list of line_id's]\n",
    "    3. Create a list of corresponding movie_id\n",
    "'''\n",
    "def get_conversations_with_movie_id():\n",
    "    conv_lines = open('./corpus/movie_conversations.txt').read().split('\\n')\n",
    "    convs = [ ]\n",
    "    movie_id = []\n",
    "    for line in conv_lines[:-1]:\n",
    "        _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"\\\\'\", \"'\").replace(\"'\",\"\").replace(\" \",\"\")\n",
    "        convs.append(_line.split(','))\n",
    "        _line = line.split(' +++$+++ ')[2]\n",
    "        movie_id.append(_line)\n",
    "    return convs, movie_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    MODIFIED!\n",
    "\n",
    "    A1: blah\n",
    "    B1: blah\n",
    "    A2: blah\n",
    "    B2: blah \n",
    "\n",
    "    are two pairs, but really two data samples for encoder and decoder \n",
    "    (Context: A1, response: B1), (Context: A1, B1, A2, response: B2). \n",
    "'''\n",
    "def gather_dataset_with_genres(convs, id2line, movie_id, id2genre, stride=2):\n",
    "    contexts = []\n",
    "    responses = []\n",
    "    genres = []\n",
    "    for conv, mid in zip(convs, movie_id):\n",
    "        # in each conversation\n",
    "        # 1, 2, ... i-1 lines are the context\n",
    "        # ith utterance will be the response\n",
    "        i = 1\n",
    "        while i < len(conv):\n",
    "            context = ''\n",
    "            for j in range(i):\n",
    "                context += ' ' + id2line[conv[j]]\n",
    "            contexts.append(context)    \n",
    "            responses.append(id2line[conv[i]])\n",
    "            genres.append(id2genre[mid])    \n",
    "            i += stride\n",
    "        \n",
    "    return contexts, responses, genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_cornell():\n",
    "    convs, movie_id = get_conversations_with_movie_id()\n",
    "    id2line = get_id2line()\n",
    "    id2genre = get_id2genre()\n",
    "    c, r, g = gather_dataset_with_genres(convs, id2line, movie_id, id2genre)\n",
    "    \n",
    "    return c, r, g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contexts, responses, genres = read_cornell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write2file(fname, data):\n",
    "    with open(fname, 'w') as f:\n",
    "        for d in data:\n",
    "            f.write(d + '\\n')\n",
    "\n",
    "write2file('context.txt', contexts)            \n",
    "write2file('response.txt', responses)\n",
    "write2file('genre.txt', genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "# 2. TOKENIZATION\n",
    "\n",
    "simply separating by space, and lowering the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    global line_counter\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" ? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "\n",
    "def load_data(data_fname):\n",
    "    \"\"\"\n",
    "    Decoder data from files, splits the data into words and generates labels.\n",
    "    Returns split sentences and labels.\n",
    "    \"\"\"\n",
    "    # Load data from files\n",
    "    examples = list(open(data_fname, \"r\").readlines())\n",
    "    \n",
    "    examples = [s.strip() for s in examples]\n",
    "    \n",
    "    # Split by words\n",
    "    tokenized_text = [clean_str(sent) for sent in examples]\n",
    "    \n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized_context = load_data('context.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN_LINE_LEN = 3\n",
    "MAX_LINE_LEN = 50\n",
    "\n",
    "lens = [len(line.split()) for line in tokenized_context]\n",
    "normlen_context = []\n",
    "normlen_genres = []\n",
    "lens = [len(line.split()) for line in tokenized_context]\n",
    "for i in range(len(tokenized_context)):\n",
    "    if lens[i] > MIN_LINE_LEN and lens[i] < MAX_LINE_LEN:\n",
    "        normlen_context.append(tokenized_context[i])\n",
    "        normlen_genres.append(genres[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98660, 138135)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normlen_context), len(tokenized_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. VOCABULARIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "learn = tf.contrib.learn\n",
    "def vocabularize(text):\n",
    "    max_document_length = max([len(x.split(\" \")) for x in text])\n",
    "    vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length, min_frequency=3)\n",
    "    x = np.array(list(vocab_processor.fit_transform(text)))\n",
    "    \n",
    "    return x, vocab_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_id, cont_vocab = vocabularize(normlen_context)\n",
    "genr_id, genr_vocab = vocabularize(normlen_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4. CREATE GENRE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genr_labels = np.zeros((len(genr_id), genr_id.max()+1), dtype=bool)\n",
    "for i, gid in enumerate(genr_id):\n",
    "    # first row is UNK token\n",
    "    genr_labels[i, gid] = True\n",
    "\n",
    "genr_labels = genr_labels[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([False, False,  True,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False], dtype=bool))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genr_id[0], genr_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 5. SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_vocab.save('context.vocab')\n",
    "np.save('context', cont_id)\n",
    "np.save('genres', genr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_id = np.load('context.npy')\n",
    "genr_labels = np.load('genres.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Origin:\n",
    "    https://github.com/dennybritz/tf-rnn/blob/master/sequence_example.ipynb\n",
    "\"\"\"\n",
    "\n",
    "def make_example(sequence, label):\n",
    "    # The object we return\n",
    "    ex = tf.train.SequenceExample()\n",
    "    # A non-sequential feature of our example\n",
    "    sequence_length = len(sequence)\n",
    "    ex.context.feature['length'].int64_list.value.append(sequence_length)\n",
    "    ex.context.feature['labels'].int64_list.value.extend(label)\n",
    "    # This part of TF is not so verbose\n",
    "    # and tutorials are rare, also serialized labels were serialized with different length\n",
    "\n",
    "    # Reshaped a bit WildML-s tips and tricks\n",
    "    # http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\n",
    "    '''\n",
    "    ex.feature_lists\\\n",
    "        .feature_list['tokens']\\\n",
    "        .feature.add()\\\n",
    "        .int64_list.value.extend(sequence)\n",
    "    '''\n",
    "    fl_tokens = ex.feature_lists.feature_list[\"tokens\"]\n",
    "    for token in sequence:\n",
    "        fl_tokens.feature.add().int64_list.value.append(token)\n",
    "    \n",
    "    return ex\n",
    "\n",
    "def write_TFRecord(fname, sequences, labels):\n",
    "    with open(fname + '.TFRecord', 'w') as fp:\n",
    "        writer = tf.python_io.TFRecordWriter(fp.name)\n",
    "        print('Sampling...')\n",
    "        i = 0\n",
    "        for sequence, label in zip(sequences, labels):\n",
    "            \n",
    "            ex = make_example(sequence, label)\n",
    "            writer.write(ex.SerializeToString())\n",
    "            \n",
    "            if i%500 == 0: print('\\r%d'%i, end='')\n",
    "            i+=1\n",
    "        writer.close()\n",
    "        print(\"\\nWrote to {}\".format(fp.name))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Origin:\n",
    "    https://indico.io/blog/tensorflow-data-inputs-part1-placeholders-protobufs-queues/\n",
    "\"\"\"\n",
    "\n",
    "def make_example(sequence, label):\n",
    "    # The object we return\n",
    "    \n",
    "    ex = tf.train.Example(features=tf.train.Features(\n",
    "    feature={\n",
    "        'labels':tf.train.Feature(\n",
    "            int64_list=tf.train.Int64List(value=label)),\n",
    "        'tokens':tf.train.Feature(\n",
    "            int64_list=tf.train.Int64List(value=sequence))\n",
    "    }))\n",
    "    return ex\n",
    "\n",
    "def write_TFRecord(fname, sequences, labels):\n",
    "    with open(fname + '.TFRecord', 'w') as fp:\n",
    "        writer = tf.python_io.TFRecordWriter(fp.name)\n",
    "        print('Sampling...')\n",
    "        i = 0\n",
    "        for sequence, label in zip(sequences, labels):\n",
    "            \n",
    "            ex = make_example(sequence, label)\n",
    "            writer.write(ex.SerializeToString())\n",
    "            \n",
    "            if i%500 == 0: print('\\r%d'%i, end='')\n",
    "            i+=1\n",
    "        writer.close()\n",
    "        print(\"\\nWrote to {}\".format(fp.name))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98500"
     ]
    }
   ],
   "source": [
    "cont_list = len(cont_id) * [None]\n",
    "for i in range(len(cont_id)):\n",
    "    cont_list[i] = np.trim_zeros(cont_id[i])\n",
    "    if i%500 == 0: print('\\r%d'%i, end='')\n",
    "#cont_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n",
      "98500\n",
      "Wrote to cnn.TFRecord\n"
     ]
    }
   ],
   "source": [
    "\n",
    "write_TFRecord('cnn', cont_list, genr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<google.protobuf.pyext._message.FieldDescriptor at 0x7f5b500d7a90>, feature {\n",
       "    key: \"labels\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 0\n",
       "        value: 1\n",
       "        value: 2\n",
       "        value: 1\n",
       "        value: 0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"tokens\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 1\n",
       "        value: 2\n",
       "        value: 3\n",
       "        value: 5\n",
       "      }\n",
       "    }\n",
       "  })]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = tf.train.Example(features=tf.train.Features(\n",
    "    feature={\n",
    "        'labels':tf.train.Feature(\n",
    "            int64_list=tf.train.Int64List(value=[0, 1, 2, 1, 0])),\n",
    "        'tokens':tf.train.Feature(\n",
    "            int64_list=tf.train.Int64List(value=[1, 2, 3, 5,])),\n",
    "    }))\n",
    "ex.ListFields()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding protobufs:\n",
    "\n",
    "http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\n",
    "\n",
    "https://indico.io/blog/tensorflow-data-inputs-part1-placeholders-protobufs-queues/\n",
    "\n",
    "At some point serialization is required, but in the example I used it isn't, but after the example is made the whole example is searialized to string.\n",
    "Very poorly documented, and unstable.\n",
    "Reading out in automated batch is described in WildML however, when\n",
    "[[1, 2, 3], [4, 5, 6, 7]] is fed as input it does not work as expected.\n",
    "\n",
    "However when reading with queues (which should be **built** in graph before being **initialized**, **coordinated** to end the reading session gracefully), the `dequeue` operator cooperates well with the `tf.train.batch` function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[(<google.protobuf.pyext._message.FieldDescriptor object at 0x7fd1f3f65790>, feature {\n",
      "  key: \"length\"\n",
      "  value {\n",
      "    int64_list {\n",
      "      value: 1\n",
      "      value: 2\n",
      "      value: 3\n",
      "    }\n",
      "  }\n",
      "}\n",
      "), (<google.protobuf.pyext._message.FieldDescriptor object at 0x7fd1f3f65190>, feature_list {\n",
      "  key: \"tokens\"\n",
      "  value {\n",
      "    feature {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "        value: 9\n",
      "        value: 9\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "ex = tf.train.SequenceExample()\n",
    "print(ex.ListFields())\n",
    "ex.context.feature['length'].int64_list.value.extend([1, 2, 3])\n",
    "# THIS IS STILL SOME BLACK MAGIC THOUGH...\n",
    "ex.context.feature['length'].int64_list.value\n",
    "ex.feature_lists.feature_list['tokens'].feature.add().int64_list.value.extend([9, 9, 9, 9])\n",
    "print(ex.ListFields())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-f99a453389d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrim_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mtrim_zeros\u001b[0;34m(filt, trim)\u001b[0m\n\u001b[1;32m   2086\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'F'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2088\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2089\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "np.trim_zeros(cont_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98660, 98660)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genr_labels), len(cont_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True, ..., False, False, False],\n",
       "       [False, False,  True, ..., False, False, False],\n",
       "       [False, False,  True, ..., False, False, False],\n",
       "       ..., \n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False]], dtype=bool)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genr_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n",
      "0features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 53\n",
      "        value: 17\n",
      "        value: 112\n",
      "        value: 18\n",
      "        value: 915\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 14\n",
      "        value: 3559\n",
      "        value: 5763\n",
      "        value: 21\n",
      "        value: 366\n",
      "        value: 87\n",
      "        value: 3751\n",
      "        value: 0\n",
      "        value: 1055\n",
      "        value: 451\n",
      "        value: 51\n",
      "        value: 29\n",
      "        value: 3\n",
      "        value: 0\n",
      "        value: 164\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "5000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 63\n",
      "        value: 1\n",
      "        value: 42\n",
      "        value: 51\n",
      "        value: 14\n",
      "        value: 1\n",
      "        value: 42\n",
      "        value: 16\n",
      "        value: 28\n",
      "        value: 214\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "10000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 946\n",
      "        value: 94\n",
      "        value: 406\n",
      "        value: 4\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 42\n",
      "        value: 29\n",
      "        value: 28\n",
      "        value: 85\n",
      "        value: 340\n",
      "        value: 29\n",
      "        value: 1241\n",
      "        value: 14\n",
      "        value: 17\n",
      "        value: 866\n",
      "        value: 46\n",
      "        value: 13\n",
      "        value: 37\n",
      "        value: 332\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "15000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "        value: 10\n",
      "        value: 1\n",
      "        value: 50\n",
      "        value: 25\n",
      "        value: 6\n",
      "        value: 10408\n",
      "        value: 58\n",
      "        value: 3\n",
      "        value: 651\n",
      "        value: 214\n",
      "        value: 18\n",
      "        value: 12\n",
      "        value: 78\n",
      "        value: 3\n",
      "        value: 2742\n",
      "        value: 9\n",
      "        value: 5\n",
      "        value: 78\n",
      "        value: 3\n",
      "        value: 2742\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "20000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2\n",
      "        value: 56\n",
      "        value: 76\n",
      "        value: 37\n",
      "        value: 318\n",
      "        value: 213\n",
      "        value: 135\n",
      "        value: 11\n",
      "        value: 5\n",
      "        value: 110\n",
      "        value: 151\n",
      "        value: 135\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "25000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 65\n",
      "        value: 37\n",
      "        value: 21\n",
      "        value: 495\n",
      "        value: 3900\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "30000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2494\n",
      "        value: 71\n",
      "        value: 4\n",
      "        value: 15\n",
      "        value: 1\n",
      "        value: 275\n",
      "        value: 163\n",
      "        value: 37\n",
      "        value: 3533\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "35000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 7\n",
      "        value: 27\n",
      "        value: 38\n",
      "        value: 147\n",
      "        value: 142\n",
      "        value: 2\n",
      "        value: 217\n",
      "        value: 4\n",
      "        value: 131\n",
      "        value: 4\n",
      "        value: 1\n",
      "        value: 38\n",
      "        value: 3\n",
      "        value: 1999\n",
      "        value: 29\n",
      "        value: 3\n",
      "        value: 115\n",
      "        value: 1562\n",
      "        value: 194\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "40000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 115\n",
      "        value: 187\n",
      "        value: 37\n",
      "        value: 14\n",
      "        value: 40\n",
      "        value: 7\n",
      "        value: 107\n",
      "        value: 8\n",
      "        value: 259\n",
      "        value: 1\n",
      "        value: 53\n",
      "        value: 33\n",
      "        value: 1069\n",
      "        value: 13\n",
      "        value: 256\n",
      "        value: 1\n",
      "        value: 56\n",
      "        value: 48\n",
      "        value: 6\n",
      "        value: 64\n",
      "        value: 4\n",
      "        value: 33\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "45000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 319\n",
      "        value: 174\n",
      "        value: 40\n",
      "        value: 6\n",
      "        value: 304\n",
      "        value: 134\n",
      "        value: 1\n",
      "        value: 232\n",
      "        value: 26\n",
      "        value: 66\n",
      "        value: 49\n",
      "        value: 12\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "50000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 216\n",
      "        value: 9292\n",
      "        value: 40\n",
      "        value: 5\n",
      "        value: 6\n",
      "        value: 936\n",
      "        value: 29\n",
      "        value: 3\n",
      "        value: 167\n",
      "        value: 459\n",
      "        value: 13\n",
      "        value: 18\n",
      "        value: 356\n",
      "        value: 90\n",
      "        value: 144\n",
      "        value: 5\n",
      "        value: 8552\n",
      "        value: 131\n",
      "        value: 4\n",
      "        value: 52\n",
      "        value: 19\n",
      "        value: 5\n",
      "        value: 64\n",
      "        value: 46\n",
      "        value: 464\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "55000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 240\n",
      "        value: 102\n",
      "        value: 4111\n",
      "        value: 1\n",
      "        value: 152\n",
      "        value: 1021\n",
      "        value: 321\n",
      "        value: 87\n",
      "        value: 2058\n",
      "        value: 190\n",
      "        value: 81\n",
      "        value: 12\n",
      "        value: 24\n",
      "        value: 286\n",
      "        value: 573\n",
      "        value: 218\n",
      "        value: 46\n",
      "        value: 2\n",
      "        value: 20\n",
      "        value: 32\n",
      "        value: 286\n",
      "        value: 573\n",
      "        value: 445\n",
      "        value: 1\n",
      "        value: 221\n",
      "        value: 33\n",
      "        value: 0\n",
      "        value: 6\n",
      "        value: 180\n",
      "        value: 96\n",
      "        value: 39\n",
      "        value: 1\n",
      "        value: 2\n",
      "        value: 47\n",
      "        value: 553\n",
      "        value: 1\n",
      "        value: 20\n",
      "        value: 7992\n",
      "        value: 13\n",
      "        value: 311\n",
      "        value: 4696\n",
      "        value: 51\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "60000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "        value: 222\n",
      "        value: 351\n",
      "        value: 7\n",
      "        value: 152\n",
      "        value: 33\n",
      "        value: 453\n",
      "        value: 173\n",
      "        value: 21\n",
      "        value: 136\n",
      "        value: 576\n",
      "        value: 29\n",
      "        value: 3\n",
      "        value: 1348\n",
      "        value: 30\n",
      "        value: 8\n",
      "        value: 406\n",
      "        value: 17\n",
      "        value: 48\n",
      "        value: 254\n",
      "        value: 882\n",
      "        value: 111\n",
      "        value: 37\n",
      "        value: 9\n",
      "        value: 21\n",
      "        value: 17\n",
      "        value: 39\n",
      "        value: 16\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "65000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "        value: 5\n",
      "        value: 111\n",
      "        value: 40\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "70000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 43\n",
      "        value: 11\n",
      "        value: 5\n",
      "        value: 61\n",
      "        value: 17\n",
      "        value: 83\n",
      "        value: 8\n",
      "        value: 42\n",
      "        value: 565\n",
      "        value: 182\n",
      "        value: 2\n",
      "        value: 72\n",
      "        value: 740\n",
      "        value: 524\n",
      "        value: 6\n",
      "        value: 1134\n",
      "        value: 1345\n",
      "        value: 397\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "75000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2\n",
      "        value: 2\n",
      "        value: 84\n",
      "        value: 11\n",
      "        value: 17\n",
      "        value: 97\n",
      "        value: 6\n",
      "        value: 6194\n",
      "        value: 4022\n",
      "        value: 7\n",
      "        value: 58\n",
      "        value: 90\n",
      "        value: 378\n",
      "        value: 14\n",
      "        value: 109\n",
      "        value: 1088\n",
      "        value: 195\n",
      "        value: 426\n",
      "        value: 14\n",
      "        value: 81\n",
      "        value: 19\n",
      "        value: 1508\n",
      "        value: 1866\n",
      "        value: 6684\n",
      "        value: 94\n",
      "        value: 33\n",
      "        value: 32\n",
      "        value: 123\n",
      "        value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "80000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 67\n",
      "        value: 1\n",
      "        value: 742\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "85000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 16\n",
      "        value: 11\n",
      "        value: 350\n",
      "        value: 2\n",
      "        value: 1252\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "90000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 21\n",
      "        value: 1\n",
      "        value: 57\n",
      "        value: 110\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "95000features {\n",
      "  feature {\n",
      "    key: \"labels\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tokens\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 10\n",
      "        value: 8\n",
      "        value: 77\n",
      "        value: 388\n",
      "        value: 38\n",
      "        value: 3\n",
      "        value: 1782\n",
      "        value: 712\n",
      "        value: 44\n",
      "        value: 10\n",
      "        value: 8\n",
      "        value: 114\n",
      "        value: 32\n",
      "        value: 167\n",
      "        value: 0\n",
      "        value: 2076\n",
      "        value: 4\n",
      "        value: 3030\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "98500\n",
      "Wrote to cnn.TFRecord\n"
     ]
    }
   ],
   "source": [
    "write_TFRecord('cnn', cont_list, genr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genr_labels.astype(float).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98660, 11)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genr_id.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_example(filename_queue):\n",
    "    # Define how to parse the example\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "    _, example = reader.read(filename_queue)\n",
    "    \n",
    "    context_features = {\n",
    "        'length': tf.FixedLenFeature([1], dtype=tf.int64),\n",
    "        'labels': tf.FixedLenFeature([24], dtype=tf.int64)\n",
    "    }\n",
    "    sequence_features = {\n",
    "        \"tokens\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "    }\n",
    "    context_parsed, sequence_parsed = tf.parse_single_sequence_example(\n",
    "        serialized=example,\n",
    "        context_features=context_features,\n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "    return context_parsed, sequence_parsed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'RuntimeError'>, Attempted to use a closed Session.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Name: , Key: labels, Index: 0.  Number of int64 values != expected.  values size: 24 but output shape: []\n\t [[Node: ParseSingleSequenceExample_22/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=2, Ncontext_sparse=0, Nfeature_list_dense=1, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64, DT_INT64], context_dense_shapes=[[], []], context_sparse_types=[], feature_list_dense_shapes=[[]], feature_list_dense_types=[DT_INT64], feature_list_sparse_types=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ReaderRead_27:1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample_22/Const, ParseSingleSequenceExample_22/Const_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/debug_name)]]\n\nCaused by op 'ParseSingleSequenceExample_22/ParseSingleSequenceExample', defined at:\n  File \"/usr/lib64/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-76-c7aaac5d9a13>\", line 2, in <module>\n    cont, seq = parse_example(filename_queue)\n  File \"<ipython-input-75-e1623355f07f>\", line 17, in parse_example\n    sequence_features=sequence_features\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/parsing_ops.py\", line 636, in parse_single_sequence_example\n    feature_list_dense_defaults, example_name, name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/parsing_ops.py\", line 833, in _parse_single_sequence_example_raw\n    name=name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 287, in _parse_single_sequence_example\n    name=name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Name: , Key: labels, Index: 0.  Number of int64 values != expected.  values size: 24 but output shape: []\n\t [[Node: ParseSingleSequenceExample_22/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=2, Ncontext_sparse=0, Nfeature_list_dense=1, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64, DT_INT64], context_dense_shapes=[[], []], context_sparse_types=[], feature_list_dense_shapes=[[]], feature_list_dense_types=[DT_INT64], feature_list_sparse_types=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ReaderRead_27:1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample_22/Const, ParseSingleSequenceExample_22/Const_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/debug_name)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Name: , Key: labels, Index: 0.  Number of int64 values != expected.  values size: 24 but output shape: []\n\t [[Node: ParseSingleSequenceExample_22/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=2, Ncontext_sparse=0, Nfeature_list_dense=1, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64, DT_INT64], context_dense_shapes=[[], []], context_sparse_types=[], feature_list_dense_shapes=[[]], feature_list_dense_types=[DT_INT64], feature_list_sparse_types=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ReaderRead_27:1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample_22/Const, ParseSingleSequenceExample_22/Const_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/debug_name)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-c7aaac5d9a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m99000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcont\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3631\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3633\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Name: , Key: labels, Index: 0.  Number of int64 values != expected.  values size: 24 but output shape: []\n\t [[Node: ParseSingleSequenceExample_22/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=2, Ncontext_sparse=0, Nfeature_list_dense=1, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64, DT_INT64], context_dense_shapes=[[], []], context_sparse_types=[], feature_list_dense_shapes=[[]], feature_list_dense_types=[DT_INT64], feature_list_sparse_types=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ReaderRead_27:1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample_22/Const, ParseSingleSequenceExample_22/Const_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/debug_name)]]\n\nCaused by op 'ParseSingleSequenceExample_22/ParseSingleSequenceExample', defined at:\n  File \"/usr/lib64/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-76-c7aaac5d9a13>\", line 2, in <module>\n    cont, seq = parse_example(filename_queue)\n  File \"<ipython-input-75-e1623355f07f>\", line 17, in parse_example\n    sequence_features=sequence_features\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/parsing_ops.py\", line 636, in parse_single_sequence_example\n    feature_list_dense_defaults, example_name, name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/parsing_ops.py\", line 833, in _parse_single_sequence_example_raw\n    name=name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 287, in _parse_single_sequence_example\n    name=name)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Name: , Key: labels, Index: 0.  Number of int64 values != expected.  values size: 24 but output shape: []\n\t [[Node: ParseSingleSequenceExample_22/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=2, Ncontext_sparse=0, Nfeature_list_dense=1, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64, DT_INT64], context_dense_shapes=[[], []], context_sparse_types=[], feature_list_dense_shapes=[[]], feature_list_dense_types=[DT_INT64], feature_list_sparse_types=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](ReaderRead_27:1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample_22/ParseSingleSequenceExample/context_dense_keys_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample_22/Const, ParseSingleSequenceExample_22/Const_1, ParseSingleSequenceExample_22/ParseSingleSequenceExample/debug_name)]]\n"
     ]
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer(['cnn.TFRecord'])\n",
    "cont, seq = parse_example(filename_queue)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for i in range(99000):\n",
    "        if i%10000==0:print(i)\n",
    "        res = cont['labels'].eval()\n",
    "        if len(res) != 24:\n",
    "            print(res)\n",
    "            break\n",
    "        #print(res)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_example(filename_queue):\n",
    "    # Define how to parse the example\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "    _, ex = reader.read(filename_queue)\n",
    "    \n",
    "    features = {\n",
    "        'tokens': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "        'labels': tf.FixedLenFeature([24], dtype=tf.int64)\n",
    "    }\n",
    "    \n",
    "    parsed = tf.parse_single_example(\n",
    "        serialized=ex,\n",
    "        features=features\n",
    "    )\n",
    "    \n",
    "    tokens = parsed['tokens']\n",
    "    labels = parsed['labels']\n",
    "    \n",
    "    return tokens, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'labels': <tf.Tensor 'ParseSingleSequenceExample_10/ParseSingleSequenceExample:0' shape=(24,) dtype=int64>,\n",
       "  'length': <tf.Tensor 'ParseSingleSequenceExample_10/ParseSingleSequenceExample:1' shape=(1,) dtype=int64>},\n",
       " {'tokens': <tf.Tensor 'ParseSingleSequenceExample_10/ParseSingleSequenceExample:2' shape=(?, 1) dtype=int64>})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer(['cnn.TFRecord'])\n",
    "parsed = parse_example(filename_queue)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a single SeqExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f7a40345a90>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension -1 must be >= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c7aaac5d9a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_input_producer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cnn.TFRecord'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-9f7009acd54a>\u001b[0m in \u001b[0;36mparse_example\u001b[0;34m(filename_queue)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mserialized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcontext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msequence_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontext_parsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_parsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_sequence_example\u001b[0;34m(serialized, context_features, sequence_features, example_name, name)\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mfeature_list_sparse_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list_dense_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       \u001b[0mfeature_list_dense_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list_dense_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m       feature_list_dense_defaults, example_name, name)\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36m_parse_single_sequence_example_raw\u001b[0;34m(serialized, context_sparse_keys, context_sparse_types, context_dense_keys, context_dense_types, context_dense_defaults, context_dense_shapes, feature_list_sparse_keys, feature_list_sparse_types, feature_list_dense_keys, feature_list_dense_types, feature_list_dense_shapes, feature_list_dense_defaults, debug_name, name)\u001b[0m\n\u001b[1;32m    813\u001b[0m                             for shape in context_dense_shapes]\n\u001b[1;32m    814\u001b[0m     feature_list_dense_shapes = [tensor_shape.as_shape(shape).as_proto()\n\u001b[0;32m--> 815\u001b[0;31m                                  for shape in feature_list_dense_shapes]\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    813\u001b[0m                             for shape in context_dense_shapes]\n\u001b[1;32m    814\u001b[0m     feature_list_dense_shapes = [tensor_shape.as_shape(shape).as_proto()\n\u001b[0;32m--> 815\u001b[0;31m                                  for shape in feature_list_dense_shapes]\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ambiguous dimension: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dimension %d must be >= 0\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension -1 must be >= 0"
     ]
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer(['cnn.TFRecord'])\n",
    "cont, seq = parse_example(filename_queue)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for i in range(99000):\n",
    "        if i%10000==0:print(i)\n",
    "        res = cont['labels'].eval()\n",
    "        if len(res) != 24:\n",
    "            print(res)\n",
    "            break\n",
    "        #print(res)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is driving me crazy\n",
    "\n",
    "```\n",
    "Name: , Key: tokens, Index: 0.  Number of int64 values != expected.  values size: 22 but output shape: []\n",
    "```\n",
    "\n",
    "however triple checked, that every single line in genre_labels are 24 length\n",
    "still serialized to 22..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read batched SeqExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in function TF_NewBuffer> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e33ace6d2f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done training -- epoch limit reached'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3631\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3633\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m       options_ptr = tf_session.TF_NewBufferFromString(\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function TF_NewBuffer> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer(['cnn.TFRecord'])\n",
    "sequence_parsed = parse_example(filename_queue)\n",
    "batched_data = tf.train.batch(\n",
    "        tensors=sequence_parsed,\n",
    "        batch_size=2,\n",
    "        dynamic_pad=True\n",
    "    )\n",
    "\n",
    "x = batched_data['tokens']\n",
    "y = batched_data['labels']\n",
    "res = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            #pass\n",
    "            res.append(x.eval().shape[1])\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        coord.request_stop()\n",
    "    #res = sess.run(sequence_parsed['tokens'])\n",
    "    #res = sess.run(sequence_parsed['tokens'])\n",
    "    #res = batched_data.eval()\n",
    "    #res1 = tf.contrib.learn.run_n({'y':batched_data})\n",
    "    #res2 = tf.contrib.learn.run_n({'y':batched_data}, n=6)\n",
    "    #print(res[0]['y'])\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14644"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n",
      "13\n",
      "13\n",
      "10\n",
      "10\n",
      "7\n",
      "7\n",
      "10\n",
      "10\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for run in res2:\n",
    "    for line in run['y']:\n",
    "        print(len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  52   13  120   16  798    0    0   19 2999    0   18  349   95 3811    0\n",
      " 1519  455   56   30    3    0  159]\n",
      "[{'y': array([[  52,   13,  120,   16,  798,    0,    0,   19, 2999,    0,   18,\n",
      "         349,   95, 3811,    0, 1519,  455,   56,   30,    3,    0,  159]])}]\n",
      "[{'y': array([[  52,   13,  120,   16,  798,    0,    0,   19, 2999,    0,   18,\n",
      "         349,   95, 3811,    0, 1519,  455,   56,   30,    3,    0,  159]])}]\n"
     ]
    }
   ],
   "source": [
    "print(res)\n",
    "print(res1)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'y': array([[  52,   13,  120,   16,  798,    0,    0,   19, 2999,    0,   18,\n",
       "           349,   95, 3811,    0, 1519,  455,   56,   30,    3,    0,  159]])}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cont_id[:10].tolist()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'length': <tf.Tensor 'ParseSingleSequenceExample_2982/ParseSingleSequenceExample:0' shape=(1,) dtype=int64>} {'tokens': <tf.Tensor 'ParseSingleSequenceExample_2982/ParseSingleSequenceExample:2' shape=(?,) dtype=int64>, 'labels': <tf.Tensor 'ParseSingleSequenceExample_2982/ParseSingleSequenceExample:1' shape=(?,) dtype=int64>}\n"
     ]
    }
   ],
   "source": [
    "filename = \"cnn.TFRecord\"\n",
    "for serialized_example in tf.python_io.tf_record_iterator(filename):\n",
    "    example = serialized_example\n",
    "    \n",
    "    context_features = {\n",
    "        \"length\" : tf.FixedLenFeature([1], dtype=tf.int64),\n",
    "    }\n",
    "    sequence_features = {\n",
    "        \"tokens\": tf.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "        \"labels\": tf.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "    }\n",
    "    context_parsed, sequence_parsed = tf.parse_single_sequence_example(\n",
    "        serialized=example,\n",
    "        context_features=context_features,\n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "    \n",
    "    # traverse the Example format to get data\n",
    "    print(context_parsed, sequence_parsed)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "Wrote to encoder-decoder.TFRecord\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./stride1-qa-16384.tfrecords\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why should I carry your bag?  I am not a dog. <<---  ['action', 'crime', 'drama', 'thriller'] --->> For five years I paid for your stupidness - you'll carry my bag for the rest of my life if I say so.  Unless you refuse, Oleg.\n",
      "\n",
      "\n",
      "Turn that off!  Get the bags. <<---  ['action', 'crime', 'drama', 'thriller'] --->> Why should I carry your bag?  I am not a dog.\n",
      "\n",
      "\n",
      "What? <<---  ['action', 'crime', 'drama', 'thriller'] --->> Smell like chemicals...for smoking drugs.\n",
      "\n",
      "\n",
      "Turn that fucking thing off! <<---  ['action', 'crime', 'drama', 'thriller'] --->> I'm not filming.  I'm watching Milos die.  It's just like a move but realer.\n",
      "\n",
      "\n",
      "You said speak Czech! <<---  ['action', 'crime', 'drama', 'thriller'] --->> How you erase this?\n",
      "\n",
      "\n",
      "Speak English! <<---  ['action', 'crime', 'drama', 'thriller'] --->> You said speak Czech!\n",
      "\n",
      "\n",
      "How you erase this? <<---  ['action', 'crime', 'drama', 'thriller'] --->> I'll do it.  Don't hurt my camera!\n",
      "\n",
      "\n",
      "Whore? <<---  ['action', 'crime', 'drama', 'thriller'] --->> I'm homesick.  You have Eastern European girl?  A Czech girl?\n",
      "\n",
      "\n",
      "Whatever we do - we fuck her, right? <<---  ['action', 'crime', 'drama', 'thriller'] --->> Oleg, get in bathroom, stay there and shut up!\n",
      "\n",
      "\n",
      "Get in the bathroom! <<---  ['action', 'crime', 'drama', 'thriller'] --->> Whatever we do - we fuck her, right?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q, a, g in zip(questions[1000:1010], answers[1000:1010], genres[1000:1010]):\n",
    "    print(q, '<<--- ', g, '--->>', a, end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
